# ============================================================
# (Deep Autoencoder ì¶”ë¡ )
# ============================================================

# ============================================================

from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import pickle
import os
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras import backend as K

def focal_loss_custom(gamma=2., alpha=0.25):
    def focal_loss_fixed(y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)
        epsilon = K.epsilon()
        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)
        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))
        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))
        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.sum((1-alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))
    return focal_loss_fixed


# ------------------------------------------------------------
# 1. Flask ì„¤ì •
# ------------------------------------------------------------
app = Flask(__name__)
CORS(app)

# ------------------------------------------------------------
# 2. íŒŒì¼ ê²½ë¡œ ì„¤ì •
# ------------------------------------------------------------
MODEL_FILE = "hobby_autoencoder.keras"
ASSETS_FILE = "model_assets.pkl"

# ì „ì—­ ë³€ìˆ˜
autoencoder = None
model_assets = None

# ------------------------------------------------------------
# 3. Hobby ID ë§¤í•‘ (DB ì—°ë™ìš©)
# ------------------------------------------------------------
hobby_id_map = {
    1: "ê·¸ë¦¼ ê·¸ë¦¬ê¸°", 2: "ìº˜ë¦¬ê·¸ë˜í”¼", 3: "ì‚¬ì§„ ì´¬ì˜", 4: "ê¸°íƒ€ ì—°ì£¼", 5: "í”¼ì•„ë…¸ ì—°ì£¼",
    6: "ìš”ê°€", 7: "í•„ë¼í…ŒìŠ¤", 8: "í—¬ìŠ¤", 9: "ëŸ¬ë‹", 10: "ìˆ˜ì˜", 12: "ìì „ê±° íƒ€ê¸°",
    13: "ì°¨ë°•", 14: "ì—¬í–‰", 15: "ê³¨í”„", 16: "ë³µì‹±", 17: "ìš”ë¦¬", 18: "ë² ì´í‚¹", 19: "ì»¤í”¼ ë¸Œë£¨ì‰",
    20: "ë…ì„œ", 21: "ì–¸ì–´ ê³µë¶€", 22: "ëœ¨ê°œì§ˆ", 23: "ë³´ì„ì‹­ììˆ˜", 24: "í¼ì¦ ë§ì¶”ê¸°", 25: "ê²Œì„",
    26: "OTT ê°ìƒ", 27: "ì˜í™” ë³´ê¸°", 28: "ìŒì•… ê°ìƒ", 29: "ì—°ê·¹ ê´€ëŒ", 30: "ì½˜ì„œíŠ¸ ê´€ëŒ",
    31: "ì•¼êµ¬ ê´€ëŒ", 32: "ì¶•êµ¬ ê´€ëŒ", 33: "í’‹ì‚´", 34: "ë°°ë“œë¯¼í„´", 35: "í´ë¼ì´ë°",
    36: "ìš”ë¦¬ í´ë˜ìŠ¤", 37: "ë””ìì¸", 38: "ì•…ê¸° ì—°ì£¼", 39: "ìº í•‘", 40: "ë“±ì‚°",
    41: "í™ˆíŠ¸ë ˆì´ë‹", 42: "ìê¸°ê³„ë°œ", 43: "ë“œë¡œì‰", 45: "ì—°ì£¼íšŒ ê°ìƒ"
}
name_to_id = {v: k for k, v in hobby_id_map.items()}

# ------------------------------------------------------------
# 4. ì…ë ¥ê°’ ì •ê·œí™” í•¨ìˆ˜
# ------------------------------------------------------------
def normalize_input_value(key, value):
    """
    ì½”ë© 4ë²ˆ ì…€ê³¼ ë™ì¼í•œ ë§¤í•‘ (í•„ìˆ˜!)
    """
    mapping = {
        "age_group": {
            "10ëŒ€": "10ëŒ€",
            "20ëŒ€ ì´ˆÂ·ì¤‘ë°˜": "20ëŒ€",
            "20ëŒ€ í›„ë°˜": "20ëŒ€",
            "30ëŒ€": "30ëŒ€",
            "40Â·50ëŒ€ ì´ìƒ": "40ëŒ€ ì´ìƒ",
        },
        "preferred_place": {
            "ì‹¤ë‚´": "ì‹¤ë‚´ì—ì„œ ì¡°ìš©íˆ í•˜ëŠ” ê±¸ ì¢‹ì•„í•´ìš”",
            "ì‹¤ì™¸": "ë°–ì—ì„œ í•˜ëŠ” ê±¸ ì¢‹ì•„í•´ìš”",
            "ìƒê´€ì—†ìŒ": "ì¥ì†Œì— í¬ê²Œ êµ¬ì• ë°›ì§€ ì•Šì•„ìš”",
        },
        "propensity": {
            "ì°½ì˜ì ": "ì°½ì˜ì ì´ê³  ê°ì„±ì ì¸ í¸ì´ì—ìš”",
            "í™œë™ì ": "í™œë™ì ì¸ í¸ì´ì—ìš”",
            "ì •ì ì¸": "ì¡°ìš©í•˜ê³  ì°¨ë¶„í•œ í¸ì´ì—ìš”",
            "ì‚¬êµì ì¸": "ìƒí™©ì— ë”°ë¼ ë‹¬ë¼ìš”",
        },
        "time_per_day": {
            "30ë¶„": "30ë¶„ ì´í•˜",
            "1ì‹œê°„": "1ì‹œê°„ ì´í•˜",
            "2ì‹œê°„": "1~2ì‹œê°„",
            "3ì‹œê°„ ì´ìƒ": "2ì‹œê°„ ì´ìƒ",
            "ìƒê´€ì—†ìŒ": "1ì‹œê°„ ì´í•˜",
        },
        "frequency": {
            "ë§¤ì¼": "ë§¤ì¼",
            "ì£¼ 2~3íšŒ": "ì£¼ 3íšŒ ì´í•˜",
            "ì£¼ 1íšŒ": "ì£¼ 3íšŒ ì´í•˜",
            "ì›” 2~3íšŒ": "ë¶ˆê·œì¹™í•˜ê²Œ í•˜ê³  ì‹¶ì–´ìš”",
            "ê°€ë”": "ë¶ˆê·œì¹™í•˜ê²Œ í•˜ê³  ì‹¶ì–´ìš”",
        },
        "hobby_time": {
            "ìƒˆë²½": "ì˜¤ì „",
            "ì˜¤ì „": "ì˜¤ì „",
            "ì˜¤í›„": "ì˜¤í›„",
            "ì €ë…": "ì €ë…",
            "ìƒê´€ì—†ìŒ": "ì£¼ë§ ì¤‘ì‹¬",
        },
        "budget": {
            "ë¬´ì˜ˆì‚° (0ì›)": "5ë§Œì› ì´í•˜",
            "ì €ì˜ˆì‚° (~5ë§Œì›)": "5ë§Œì› ì´í•˜",
            "ì €ì˜ˆì‚°": "5ë§Œì› ì´í•˜",
            "ì¤‘ê°„ (5~15ë§Œì›)": "5ë§Œì› ~ 10ë§Œì›",
            "ì¤‘ê°„": "5ë§Œì› ~ 10ë§Œì›",
            "ê³ ì˜ˆì‚° (15ë§Œì›~)": "10ë§Œì› ì´ìƒ",
            "ìƒê´€ì—†ìŒ": "5ë§Œì› ì´í•˜",
        },
        "goal": {
            "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ": "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ ë° íë§",
            "ìê¸°ê³„ë°œ": "ìê¸°ê³„ë°œ",
            "ì‚¬íšŒì  êµë¥˜": "ì‚¬ëŒë“¤ê³¼ì˜ êµë¥˜",
            "ê±´ê°•ê´€ë¦¬": "ì„±ì·¨ê°ê³¼ ë§Œì¡±ê°",
        },
        "sociality": {
            "í˜¼ì": "í˜¼ì í•˜ëŠ” ê±¸ ì„ í˜¸í•´ìš”",
            "í•¨ê»˜": "í•¨ê»˜ í•˜ëŠ” ê±¸ ì„ í˜¸í•´ìš”",
            "ìƒê´€ì—†ìŒ": "ìƒí™©ì— ë”°ë¼ ë‹¬ë¼ìš”",
        },
    }

    # ë§¤í•‘ì— ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    return mapping.get(key, {}).get(value, value)




# ------------------------------------------------------------
# 5. ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# ------------------------------------------------------------
def load_model_files():
    global autoencoder, model_assets
    
    print("\n[ë¡œë”© ì‹œì‘] ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    
    try:
        # 1. Keras ëª¨ë¸ ë¡œë“œ
        if os.path.exists(MODEL_FILE):
            custom_objects = {'focal_loss_fixed': focal_loss_custom(gamma=2.0, alpha=0.25)}
            autoencoder = load_model(MODEL_FILE, custom_objects=custom_objects)

            print(f"ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {MODEL_FILE}")
        else:
            print(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {MODEL_FILE}")
            return
        
        # 2. ì „ì²˜ë¦¬ ë„êµ¬ + Threshold ë¡œë“œ
        if os.path.exists(ASSETS_FILE):
            with open(ASSETS_FILE, 'rb') as f:
                model_assets = pickle.load(f)
            print(f"ì „ì²˜ë¦¬ ë„êµ¬ ë¡œë“œ ì„±ê³µ: {ASSETS_FILE}")
            print(f"   í•™ìŠµ ì •ë³´: {model_assets.get('info', {})}")
            print(f"   Threshold: {model_assets.get('optimal_threshold', 0.5):.3f}")
        else:
            print(f"PKL íŒŒì¼ ì—†ìŒ: {ASSETS_FILE}")
            return
            
        print("=" * 60)
        print("ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ Threshold ê¸°ë°˜ ì¶”ë¡  í™œì„±í™”")
        print("=" * 60)
        
    except Exception as e:
        print(f"ë¡œë“œ ì‹¤íŒ¨: {e}")

# ------------------------------------------------------------
# 6. ì¶”ì²œ í•¨ìˆ˜ ê°œì„  (Threshold ê¸°ë°˜)
# ------------------------------------------------------------
def recommend_hobbies_improved(user_answers, min_recommendations=3, max_recommendations=10):

    if not autoencoder or not model_assets:
        print("[ERROR] ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    # 1. pklì—ì„œ í•„ìš”í•œ ë„êµ¬ êº¼ë‚´ê¸°
    feature_columns = model_assets['feature_columns']
    scaler = model_assets['scaler']
    hobby_labels = model_assets['hobby_labels']
    optimal_threshold = model_assets.get('optimal_threshold', 0.5)
    
    # 2. ì‚¬ìš©ì ì…ë ¥ â†’ One-Hot Encoding
    user_df = pd.DataFrame([user_answers])
    user_encoded = pd.get_dummies(user_df)
    
    # 3. í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì»¬ëŸ¼ ìˆœì„œë¡œ ë§ì¶”ê¸°
    X_input = user_encoded.reindex(columns=feature_columns, fill_value=0).values
    
        
    # 4. ë¨¼ì € user featuresë§Œ ìŠ¤ì¼€ì¼ë§ (41ê°œ)
    X_input_scaled = scaler.transform(X_input)

    # 5. ê°€ì¤‘ì¹˜ ì ìš© (propensityì—ë§Œ ì•½ê°„)
    weights = {
        'propensity': 2.5,  # ì„±í–¥ì—ë§Œ ì¡°ê¸ˆ ê°€ì¤‘ì¹˜
        'budget' : 1.5,
        'default': 1.0
    }

    num_user_features = len(feature_columns)
    for i, col in enumerate(feature_columns):
        if i >= num_user_features:
            break
        w = weights['propensity'] if 'propensity' in col else weights['default']
        X_input_scaled[0, i] *= w

    # 6. Zero Padding (ì·¨ë¯¸ ë¶€ë¶„)
    dummy_hobbies = np.zeros((1, len(hobby_labels)))

    # 7. ìŠ¤ì¼€ì¼ë§ëœ user features + zero hobbies ê²°í•©
    full_input_scaled = np.hstack([X_input_scaled, dummy_hobbies])

    # 8. ì˜¤í† ì¸ì½”ë” ì˜ˆì¸¡
    reconstructed = autoencoder.predict(full_input_scaled, verbose=0)

    # 9. ë’·ë¶€ë¶„(ì·¨ë¯¸ íŒŒíŠ¸)ë§Œ ì¶”ì¶œ
    predicted_scores = reconstructed[0, -len(hobby_labels):]
    
    # 10. Threshold ê¸°ë°˜ í•„í„°ë§
    hobby_score_pairs = [
        (label, float(score)) 
        for label, score in zip(hobby_labels, predicted_scores)
        if score >= optimal_threshold  # Threshold ì´ìƒë§Œ ì„ íƒ
    ]
    
    # 11. ì ìˆ˜ ìˆœ ì •ë ¬
    hobby_score_pairs.sort(key=lambda x: x[1], reverse=True)
    
    # 12. ìµœì†Œ/ìµœëŒ€ ê°œìˆ˜ ë³´ì¥
    if len(hobby_score_pairs) < min_recommendations:
        # Threshold ì´í•˜ì§€ë§Œ ìƒìœ„ Nê°œ ì¶”ê°€
        all_hobbies = sorted(
            [(label, float(score)) for label, score in zip(hobby_labels, predicted_scores)],
            key=lambda x: x[1],
            reverse=True
        )
        hobby_score_pairs = all_hobbies[:min_recommendations]
    
    # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
    hobby_score_pairs = hobby_score_pairs[:max_recommendations]
    
    # 13. Confidenceë¥¼ 0~100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    # 260ì¤„ ë¶€ë¶„ì„ ì´ë ‡ê²Œ ë³€ê²½
    results = []
    for hobby, score in hobby_score_pairs:
        # Sigmoidë¡œ 0~1 ë²”ìœ„ë¡œ ë³€í™˜ í›„ 100 ê³±í•˜ê¸°
        normalized = 1 / (1 + np.exp(-10 * (score - 0.5)))
        confidence = round(normalized * 100, 1)
        results.append((hobby, max(confidence, 1.0)))
    
    return results

# ------------------------------------------------------------
# 7. API ë¼ìš°íŠ¸
# ------------------------------------------------------------
@app.route("/")
def home():
    status = "active" if autoencoder else "inactive"
    threshold = model_assets.get('optimal_threshold', 'N/A') if model_assets else 'N/A'
    
    return jsonify({
        "status": status,
        "model": "Improved Deep Autoencoder (Threshold-based)",
        "threshold": float(threshold) if isinstance(threshold, (int, float)) else threshold,
        "hobbies_count": len(model_assets['hobby_labels']) if model_assets else 0
    })

@app.route("/recommend", methods=["POST"])
def recommend():
    try:
        user_data = request.get_json()
        if not user_data:
            return jsonify({"error": "No data provided"}), 400
        
        print(f"[ìš”ì²­ ë°›ìŒ] {user_data}")
        
        # í•„ìˆ˜ í•„ë“œ ì²´í¬
        required_fields = [
            "gender", "age_group", "preferred_place", "propensity", 
            "budget", "hobby_time", "time_per_day", "frequency", 
            "goal", "sociality"
        ]
        
        # ëª¨ë“  í•„ë“œê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        is_empty = True
        for field in required_fields:
            val = user_data.get(field)
            if val and str(val).strip() != "":
                is_empty = False
                break
        
        if is_empty:
            return jsonify({
                "recommended_ids": [],
                "recommended_hobbies": [],
                "confidence": []
            })
        
        # ì…ë ¥ê°’ ì •ê·œí™”
        #normalized = {k: normalize_input_value(k, v) for k, v in user_data.items()}

        
        
        # ê°œì„ ëœ ì¶”ì²œ ì‹¤í–‰ (Threshold ê¸°ë°˜)
        #recs = recommend_hobbies_improved(normalized, min_recommendations=5, max_recommendations=10)
        
        # ì •ê·œí™” ì—†ì´ ì›ë³¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ëª¨ë¸ì— ë„£ìŒ
        print(f"[ì…ë ¥ ë°ì´í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©] {user_data}")
        recs = recommend_hobbies_improved(user_data, min_recommendations=5, max_recommendations=10)
        
        # ê²°ê³¼ íŒŒì‹±
        hobby_names = [h[0] for h in recs]
        hobby_probs = [h[1] for h in recs]
        hobby_ids = [name_to_id.get(h, 0) for h in hobby_names]
        
        print(f"[ì¶”ì²œ ê²°ê³¼] {hobby_names[:5]}")  # ìƒìœ„ 5ê°œë§Œ ë¡œê·¸
        print(f"[Confidence] {hobby_probs[:5]}")
        
        return jsonify({
            "recommended_ids": hobby_ids,
            "recommended_hobbies": hobby_names,
            # "confidence": hobby_probs
        })
    
    except Exception as e:
        print(f"[ì˜¤ë¥˜ ë°œìƒ] {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# ------------------------------------------------------------
# 8. ì„œë²„ ì‹¤í–‰
# ------------------------------------------------------------
if __name__ == "__main__":
    # ì„œë²„ ì‹œì‘ ì „ì— ëª¨ë¸ ë¡œë“œ
    load_model_files()
    
    print("\n" + "=" * 60)
    print("ğŸš€ Flask ì„œë²„ ì‹œì‘ (ê°œì„ ëœ Threshold ê¸°ë°˜ ì¶”ë¡ )")
    print("=" * 60)
    
    app.run(host="0.0.0.0", port=5000, debug=False)

